{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/AnanyaThyagarajan/Python-Projects/main/Movie%20Recommend/Tamil_movies_dataset.csv'\n",
    "data_movies = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "import os\n",
    "import email\n",
    "import email.policy\n",
    "from email.parser import BytesParser\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import pickle\n",
    "\n",
    "def download__file(url, save_path):\n",
    "    \"\"\"Downloads a file from a URL to the specified local path.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "    else:\n",
    "        print(f\"Failed to download {url}\")\n",
    "\n",
    "def extract__tarfile(file_path, extract_path=\".\"):\n",
    "    \"\"\"Extracts a tar.bz2 file to the specified directory.\"\"\"\n",
    "    with tarfile.open(file_path, \"r:bz2\") as file:\n",
    "        file.extractall(path=extract_path)\n",
    "\n",
    "def load_emails_from_directory(directory):\n",
    "    \"\"\"Loads all emails from the specified directory, parsing them for text content.\"\"\"\n",
    "    emails = []\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        with open(filepath, 'rb') as file:\n",
    "            msg = BytesParser(policy=email.policy.default).parse(file)\n",
    "            email_body = msg.get_body(preferencelist=('plain', 'html')).get_content()\n",
    "            emails.append(email_body)\n",
    "    return emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# URLs of your GitHub-hosted files (replace these with the actual URLs)\n",
    "urls = [\n",
    "    'https://raw.githubusercontent.com/AnanyaThyagarajan/Spam-Detection/main/Dataset/20030228_spam_2.tar.bz2',\n",
    "    'https://raw.githubusercontent.com/AnanyaThyagarajan/Spam-Detection/main/Dataset/20050311_spam_2.tar.bz2',\n",
    "    'https://raw.githubusercontent.com/AnanyaThyagarajan/Spam-Detection/main/Dataset/20030228_easy_ham_2.tar.bz2',\n",
    "    'https://raw.githubusercontent.com/AnanyaThyagarajan/Spam-Detection/main/Dataset/20030228_hard_ham.tar.bz2'\n",
    "]\n",
    "files = ['20030228_spam_2.tar.bz2', '20050311_spam_2.tar.bz2', '20021010_easy_ham.tar.bz2', '20021010_hard_ham.tar.bz2']\n",
    "directories = ['20030228_spam_2', '20050311_spam_2', '20021010_easy_ham', '20021010_hard_ham']\n",
    "\n",
    "# Download and extract files\n",
    "for url, file, directory in zip(urls, files, directories):\n",
    "    download__file(url, file)\n",
    "    extract__tarfile(file, directory)\n",
    "\n",
    "# Load emails and label them\n",
    "data_frames = []\n",
    "for directory, label in zip(directories, [1, 1, 0, 0]):  # spam = 1, ham = 0\n",
    "    emails = load_emails_from_directory(directory)\n",
    "    df = pd.DataFrame(emails, columns=['message'])\n",
    "    df['label'] = label\n",
    "    data_frames.append(df)\n",
    "\n",
    "# Combine datasets\n",
    "combined_data = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_data['message'], combined_data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# SVM Model\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and Evaluate\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Save model and vectorizer\n",
    "pickle.dump(model, open('spam_svm_model.pkl', 'wb'))\n",
    "pickle.dump(vectorizer, open('tfidf_vectorizer.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import email  # for parsing emails\n",
    "import pickle\n",
    "\n",
    "def parse__email(text):\n",
    "    \"\"\"Parse email from text to extract plain text content.\"\"\"\n",
    "    try:\n",
    "        msg = email.message_from_string(text)\n",
    "        for part in msg.walk():\n",
    "            if part.get_content_type() == 'text/plain':\n",
    "                return part.get_payload()\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "# Load your dataset here (make sure it's properly formatted with 'label' and 'message' columns)\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/AnanyaThyagarajan/Python-Projects/main/Movie%20Recommend/Tamil_movies_dataset.csv'\n",
    "data_ = pd.read_csv(url)\n",
    "data = pd.read_csv('combined_dataset.csv')\n",
    "data['message'] = data['message'].apply(parse_email)\n",
    "\n",
    "# Label encoding (if not already done)\n",
    "data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['message'], data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# SVM Model\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and Evaluate\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Save model and vectorizer\n",
    "pickle.dump(model, open('spam_svm_model.pkl', 'wb'))\n",
    "pickle.dump(vectorizer, open('tfidf_vectorizer.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
